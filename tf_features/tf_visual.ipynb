{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gyotus84aod9"
   },
   "outputs": [],
   "source": [
    "import io  # 文件数据流\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# 导入常见网络层, sequential容器, 优化器, 损失函数\n",
    "from tensorflow.keras import layers, Sequential, optimizers, losses, metrics\n",
    "import os # 运维模块， 调用系统命令\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 只显示warring和error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WLUmcvdartW"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()  # 在内存中存储画\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # 传化为TF 图\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_grid(images):\n",
    "    # 返回一个5x5的mnist图像\n",
    "    figure  = plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1, title='name')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "1JduUFSmaw9E",
    "outputId": "8ba089b8-50c0-47d5-99e1-6a00c6e053cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "datasets: (60000, 28, 28) (60000,) 0 255\n"
     ]
    }
   ],
   "source": [
    "batchsz = 128\n",
    "path = r'./mnist.npz'\n",
    "(x, y), (x_val, y_val) = tf.keras.datasets.mnist.load_data(path)\n",
    "print('datasets:', x.shape, y.shape, x.min(), x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcIgPD_ba2k7"
   },
   "outputs": [],
   "source": [
    "db = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ZLAdMSSGa3o-",
    "outputId": "3e039f79-12d7-4009-d9e7-ac06eb8dd449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network = Sequential([\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "optimizer=optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcp8XdIla8dj"
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/' + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)  # 创建监控类，监控数据写入到log_dir目录\n",
    "\n",
    "sample_img = next(iter(db))[0]\n",
    "sample_img = sample_img[0]  # 第一张图\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "with summary_writer.as_default():  # 写入环境\n",
    "    tf.summary.image(\"Training sample:\", sample_img, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "id": "-18MUq1Da-zz",
    "outputId": "599e5f8f-80df-44cc-f5d8-25ca227099c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 2.326235771179199\n",
      "0 Evaluate Acc: 0.1346153846153846\n",
      "100 loss: 0.40445271134376526\n",
      "200 loss: 0.17955899238586426\n",
      "300 loss: 0.2395472228527069\n",
      "400 loss: 0.22995679080486298\n",
      "500 loss: 0.10855032503604889\n",
      "500 Evaluate Acc: 0.9526241987179487\n",
      "600 loss: 0.11299649626016617\n",
      "700 loss: 0.18857276439666748\n",
      "800 loss: 0.09502774477005005\n",
      "900 loss: 0.12557914853096008\n",
      "1000 loss: 0.10354170203208923\n",
      "1000 Evaluate Acc: 0.9581330128205128\n",
      "1100 loss: 0.06277208030223846\n",
      "1200 loss: 0.15149468183517456\n",
      "1300 loss: 0.1416153907775879\n",
      "1400 loss: 0.037692729383707047\n",
      "1500 loss: 0.09318254888057709\n",
      "1500 Evaluate Acc: 0.9625400641025641\n",
      "1600 loss: 0.13104911148548126\n",
      "1700 loss: 0.0459851510822773\n",
      "1800 loss: 0.087934710085392\n",
      "1900 loss: 0.016891684383153915\n",
      "2000 loss: 0.07304257899522781\n",
      "2000 Evaluate Acc: 0.9686498397435898\n",
      "2100 loss: 0.1368153691291809\n",
      "2200 loss: 0.18466390669345856\n",
      "2300 loss: 0.10615689307451248\n",
      "2400 loss: 0.07346498966217041\n",
      "2500 loss: 0.11300792545080185\n",
      "2500 Evaluate Acc: 0.9674479166666666\n",
      "2600 loss: 0.04543505609035492\n",
      "2700 loss: 0.04615473002195358\n",
      "2800 loss: 0.22267162799835205\n",
      "2900 loss: 0.030948804691433907\n",
      "3000 loss: 0.1332511454820633\n",
      "3000 Evaluate Acc: 0.9780649038461539\n",
      "3100 loss: 0.1442835032939911\n",
      "3200 loss: 0.13262832164764404\n",
      "3300 loss: 0.04702862352132797\n",
      "3400 loss: 0.02274300344288349\n",
      "3500 loss: 0.11909618973731995\n",
      "3500 Evaluate Acc: 0.9754607371794872\n",
      "3600 loss: 0.04978146776556969\n",
      "3700 loss: 0.02797735668718815\n",
      "3800 loss: 0.0030006403103470802\n",
      "3900 loss: 0.12144213914871216\n",
      "4000 loss: 0.11768180131912231\n",
      "4000 Evaluate Acc: 0.9714543269230769\n",
      "4100 loss: 0.0968778133392334\n",
      "4200 loss: 0.02460096776485443\n",
      "4300 loss: 0.019437383860349655\n",
      "4400 loss: 0.1348620057106018\n",
      "4500 loss: 0.03999219834804535\n",
      "4500 Evaluate Acc: 0.9730568910256411\n",
      "4600 loss: 0.09932027012109756\n"
     ]
    }
   ],
   "source": [
    "for step, (x, y) in enumerate(db):    # 遍历切分好的数据step:0->599\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        out = network(x)\n",
    "        y = tf.one_hot(y, depth=10)\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, out, from_logits=True))\n",
    "\n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, 'loss:', float(loss))  # 读统计数据\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('train-loss', float(loss), step=step)  # 将loss写入到train-loss中\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        total, total_correct = 0., 0\n",
    "\n",
    "        for _, (m, n) in enumerate(ds_val):\n",
    "            m = tf.reshape(m, (-1, 28*28))\n",
    "            out = network(m)\n",
    "            pred = tf.argmax(out, axis=1)\n",
    "            pred = tf.cast(pred, dtype=tf.int32)\n",
    "            correct = tf.equal(pred, n)\n",
    "            total_correct += tf.reduce_sum(tf.cast(correct, dtype=tf.int32)).numpy()\n",
    "            total += m.shape[0]\n",
    "\n",
    "        print(step, 'Evaluate Acc:', total_correct / total)\n",
    "\n",
    "        val_images = m[:25]\n",
    "        val_images = tf.reshape(val_images, [-1, 28, 28, 1])\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('test-acc', float(total_correct / total), step=step)  # 写入测试准确率\n",
    "            tf.summary.image(\"val-onebyone-images:\", val_images, max_outputs=25, step=step)  # 可视化测试用图片，25张\n",
    "            val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "            figure = image_grid(val_images)\n",
    "            tf.summary.image('val-images:', plot_to_image(figure), step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir \"./log\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "tf_visual.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
